{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DzZ5GWFr8SKM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (replace 'your_data.csv' with the path to your uploaded file)\n",
        "df = pd.read_excel('data_report2.xlsx')\n",
        "\n",
        "# Assuming the dataframe `df` is as per the structure seen in the screenshot:\n",
        "# Convert 'Y'/'N' columns to boolean True/False\n",
        "boolean_columns = ['frisked', 'searched', 'pistol', 'pf_hcuff']\n",
        "for col in boolean_columns:\n",
        "    df[col] = df[col] == 'Y'\n",
        "\n",
        "# Create a new dataframe where each row represents a transaction\n",
        "# and each transaction contains a set of items\n",
        "transactions = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    transaction = set()\n",
        "    for col in boolean_columns:\n",
        "        if row[col]:\n",
        "            transaction.add(col)\n",
        "    # Add other categorical attributes as items\n",
        "    transaction.add(f\"race_{row['race']}\")\n",
        "    transaction.add(f\"sex_{row['sex']}\")\n",
        "    transaction.add(f\"crimsusp_{row['crimsusp']}\")\n",
        "    transaction.add(f\"city_{row['city']}\")\n",
        "\n",
        "    transactions.append(transaction)\n",
        "\n",
        "# Now, `transactions` is a list of sets, where each set is a transaction\n",
        "\n",
        "# Example: a CSV where each row is a transaction and items are comma-separated\n",
        "with open('transactions.csv', 'w') as f:\n",
        "    for transaction in transactions:\n",
        "        f.write(','.join(transaction) + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NykEaEQSAeg5",
        "outputId": "7eb8b371-878a-4804-c867-7a12942f31b2"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 3.40 GiB for an array with shape (532911, 6844) and data type bool",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming transactions is a list of lists, where each sublist is a list of items in a transaction\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# For example: transactions = [['milk', 'bread'], ['bread', 'diapers'], ...]\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 1: One-hot encode the transaction data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m te \u001b[38;5;241m=\u001b[39m TransactionEncoder()\n\u001b[1;32m---> 11\u001b[0m te_ary \u001b[38;5;241m=\u001b[39m te\u001b[38;5;241m.\u001b[39mfit(transactions)\u001b[38;5;241m.\u001b[39mtransform(transactions)\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(te_ary, columns\u001b[38;5;241m=\u001b[39mte\u001b[38;5;241m.\u001b[39mcolumns_)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Step 2: Use the apriori algorithm to find frequent itemsets\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\mlxtend\\preprocessing\\transactionencoder.py:125\u001b[0m, in \u001b[0;36mTransactionEncoder.transform\u001b[1;34m(self, X, sparse)\u001b[0m\n\u001b[0;32m    123\u001b[0m     array \u001b[38;5;241m=\u001b[39m csr_matrix((non_sparse_values, indices, indptr), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(X), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns_)), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row_idx, transaction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m transaction:\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.40 GiB for an array with shape (532911, 6844) and data type bool"
          ]
        }
      ],
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# One-hot encode the transaction data\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Using the apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)  # adjust the min_support as necessary\n",
        "\n",
        "# Generating association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)  # adjust the min_threshold as necessary\n",
        "\n",
        "# Displaying tables of frequent itemsets and association rules\n",
        "print(frequent_itemsets)\n",
        "print(rules)\n",
        "\n",
        "# Visualization of results:\n",
        "\n",
        "# Frequent Itemsets Visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=frequent_itemsets['support'], y=frequent_itemsets['itemsets'].astype(str))\n",
        "plt.title('Frequent Itemsets')\n",
        "plt.xlabel('Support')\n",
        "plt.ylabel('Itemsets')\n",
        "plt.show()\n",
        "\n",
        "# Association Rules Visualization\n",
        "import numpy as np\n",
        "\n",
        "# Let's assume 'rules' is your DataFrame and it has a 'lift' column.\n",
        "# We add small random noise to 'support' and 'confidence' to prevent overlapping.\n",
        "support_jitter = rules['support'] + np.random.uniform(-0.0005, 0.0005, size=len(rules))\n",
        "confidence_jitter = rules['confidence'] + np.random.uniform(-0.0005, 0.0005, size=len(rules))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(support_jitter, confidence_jitter, alpha=0.5, c=rules['lift'], cmap='viridis')\n",
        "plt.title('Association Rules - Support vs Confidence Colored by Lift')\n",
        "plt.xlabel('Support')\n",
        "plt.ylabel('Confidence')\n",
        "plt.colorbar(scatter, label='Lift')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
