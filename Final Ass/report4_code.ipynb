{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhhodiPcSOb0",
        "outputId": "247300f2-34c2-4fd3-8bc9-ff6472f3955d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Saymon\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.6011\n",
            "Precision: 0.6115\n",
            "Recall: 0.6011\n",
            "F1 Score: 0.5500\n",
            "AUC-ROC: 0.6011\n",
            "Cross-Validation Scores: [0.60321816 0.60391012 0.6046138  0.6030024  0.60603999]\n",
            "CV Mean: 0.6042\n",
            "CV Std: 0.0011\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.6104\n",
            "Precision: 0.6075\n",
            "Recall: 0.6104\n",
            "F1 Score: 0.5894\n",
            "AUC-ROC: 0.6185\n",
            "Cross-Validation Scores: [0.61011423 0.60820257 0.61019633 0.60860846 0.61345218]\n",
            "CV Mean: 0.6101\n",
            "CV Std: 0.0018\n",
            "\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.5574\n",
            "Precision: 0.5812\n",
            "Recall: 0.5574\n",
            "F1 Score: 0.3993\n",
            "AUC-ROC: 0.4419\n",
            "Cross-Validation Scores: [0.55800671 0.5579598  0.43181338 0.55796634 0.44202193]\n",
            "CV Mean: 0.5096\n",
            "CV Std: 0.0594\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Loading your dataset\n",
        "df = pd.read_excel('data_report4.xlsx')\n",
        "\n",
        "# Preprocessing data: Encode categorical variables\n",
        "le_race = LabelEncoder()\n",
        "df['race_encoded'] = le_race.fit_transform(df['race'])\n",
        "le_sex = LabelEncoder()\n",
        "df['sex_encoded'] = le_sex.fit_transform(df['sex'])\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = df[['age', 'race_encoded', 'sex_encoded']]\n",
        "y = df['frisked']\n",
        "\n",
        "# Binary encode the target\n",
        "le_frisked = LabelEncoder()\n",
        "y = le_frisked.fit_transform(y)\n",
        "\n",
        "# Splitting data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Creating classification models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=10, n_jobs=-1),\n",
        "    'Support Vector Machine': SVC(kernel='linear', max_iter=1000, probability=True)  # Enable probability\n",
        "}\n",
        "\n",
        "# Empty dict to hold model performances\n",
        "model_performance = {}\n",
        "\n",
        "# Evaluating each model\n",
        "for name, model in models.items():\n",
        "    # Fitting the model on the training data\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    # Making predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    # Generating classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    # Checking if the model has predict_proba method\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
        "    else:\n",
        "        # If predict_proba is not available, set AUC-ROC to None\n",
        "        roc_auc = None\n",
        "    # Performing cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "    # Aggregating the results\n",
        "    model_performance[name] = {\n",
        "        'Accuracy': report['accuracy'],\n",
        "        'Precision': report['weighted avg']['precision'],\n",
        "        'Recall': report['weighted avg']['recall'],\n",
        "        'F1 Score': report['weighted avg']['f1-score'],\n",
        "        'AUC-ROC': roc_auc,\n",
        "        'Cross-Validation Scores': cv_scores,\n",
        "        'CV Mean': cv_scores.mean(),\n",
        "        'CV Std': cv_scores.std()\n",
        "    }\n",
        "\n",
        "# Displaying model performances\n",
        "for model, performance in model_performance.items():\n",
        "    print(f\"Model: {model}\")\n",
        "    for metric, value in performance.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "        elif value is not None:\n",
        "            print(f\"{metric}: {value}\")\n",
        "    print(\"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
